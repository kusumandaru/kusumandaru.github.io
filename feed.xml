<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Kusumandaru</title>
    <description>Collection of medium story</description>
    <link>https://kusumandaru.com/</link>
    <atom:link href="https://kusumandaru.com/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Thu, 31 Dec 2020 08:21:38 +0700</pubDate>
    <lastBuildDate>Thu, 31 Dec 2020 08:21:38 +0700</lastBuildDate>
    <generator>Jekyll v3.9.0</generator>
    
      <item>
        <title>Mask Detector using TensorFlow Lite</title>
        <description>&lt;p&gt;It can use Raspberry Pi or Macbook Pro and send into slack, even use 4 USD webcam&lt;/p&gt;
&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/0*bGD2Rzp4-Qqax5_M&quot; /&gt;&lt;figcaption&gt;Photo by &lt;a href=&quot;https://unsplash.com/@adamsky1973?utm_source=medium&amp;amp;utm_medium=referral&quot;&gt;Adam Nieścioruk&lt;/a&gt; on &lt;a href=&quot;https://unsplash.com?utm_source=medium&amp;amp;utm_medium=referral&quot;&gt;Unsplash&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Since some people don’t have sense of concern to use facemask on public area. Our office have regulation to assign some people to be watcher and take a record of image people which stubborn or forget. Furthermore it will took my time to watch surrounding and keep eye of my friend.&lt;/p&gt;
&lt;p&gt;Because of that Isearch and found repository of &lt;a href=&quot;https://github.com/AIZOOTech/FaceMaskDetection&quot;&gt;Facemask detection&lt;/a&gt; and give some improvement to save image when some frame was detected and send into slack.&lt;/p&gt;
&lt;p&gt;In Indonesia, you can bought equipment here:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://www.tokopedia.com/rajacell/kamera-usb-camera-8mp-untuk-raspberry-pi-3-model-b-kabel-tarik-retrack&quot;&gt;Cheap webcam camera&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://www.bukalapak.com/p/komputer/mini-pc/3dyw77y-jual-raspberry-pi-4-model-b-ram-8-gb-siap-pakai?product_sku=7399366470&quot;&gt;Raspberry Pi 4 Complete&lt;/a&gt;, it is already include case, memory card, and power cable, since it using dash cam, try to get usb cable. Or use some laptop /computer.&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://www.tokopedia.com/rajacell/3pcs-black-aluminium-heatsink-pendingin-heat-sink-raspberry-pi-4-b-3b&quot;&gt;Heatsink&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://www.tokopedia.com/rajacell/wireless-mini-keyboard-rii-mini-i8-2-4g-touchpad-remote-support-raspi-hitam&quot;&gt;Keyboard wireless&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;This program is consist of several part:&lt;/p&gt;
&lt;p&gt;Load Image Model&lt;/p&gt;
&lt;pre&gt;sess, graph = load_tf_model(&amp;#39;models/face_mask_detection.pb&amp;#39;)&lt;/pre&gt;
&lt;p&gt;Send image to tensorflow detection (Receive an image array and run inference). It have detection inference with several params:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;image: 3D numpy array of image&lt;/li&gt;&lt;li&gt;conf_thresh: the min threshold of classification probabity.&lt;/li&gt;&lt;li&gt;iou_thresh: the IOU threshold of NMS&lt;/li&gt;&lt;li&gt;target_shape: the model input size.&lt;/li&gt;&lt;li&gt;draw_result: whether to draw bounding box to the image.&lt;/li&gt;&lt;li&gt;show_result: whether to display the image.&lt;/li&gt;&lt;/ul&gt;
&lt;pre&gt;y_bboxes_output, y_cls_output = tf_inference(sess, graph, image_exp)&lt;/pre&gt;
&lt;p&gt;y_bboxes_output will return box detection coordinate&lt;/p&gt;
&lt;p&gt;y_cls_output will return score of confidence image have using proper mask or not&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;set label&lt;/li&gt;&lt;/ul&gt;
&lt;pre&gt;id2class = {0: &amp;#39;Mask&amp;#39;, 1: &amp;#39;NoMask&amp;#39;}&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;write image&lt;/li&gt;&lt;/ul&gt;
&lt;pre&gt;cv2.imwrite(filename_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;send to slack&lt;/li&gt;&lt;/ul&gt;
&lt;pre&gt;requests.post(&lt;/pre&gt;
&lt;pre&gt;&amp;#39;https://slack.com/api/files.upload&amp;#39;,&lt;/pre&gt;
&lt;pre&gt;{&lt;/pre&gt;
&lt;pre&gt;&amp;#39;token&amp;#39;: slack_token,&lt;/pre&gt;
&lt;pre&gt;&amp;#39;filename&amp;#39;: file_name,&lt;/pre&gt;
&lt;pre&gt;&amp;#39;channels&amp;#39;: slack_channel,&lt;/pre&gt;
&lt;pre&gt;&amp;#39;filetype&amp;#39;: file_type,&lt;/pre&gt;
&lt;pre&gt;&amp;#39;initial_comment&amp;#39;: text,&lt;/pre&gt;
&lt;pre&gt;&amp;#39;title&amp;#39;: title&lt;/pre&gt;
&lt;pre&gt;},&lt;/pre&gt;
&lt;pre&gt;files = { &amp;#39;file&amp;#39;: file_bytes }).json()&lt;/pre&gt;
&lt;p&gt;To running follow these step:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;git clone these repository&lt;/li&gt;&lt;li&gt;create virtual environment -&amp;gt; virtual env facemask&lt;/li&gt;&lt;li&gt;activate virtual environemnt -&amp;gt; source facemask/bin/activate&lt;/li&gt;&lt;li&gt;copy env -&amp;gt; cp .env.staging .env&lt;/li&gt;&lt;li&gt;update env value with slack channel and slack token&lt;/li&gt;&lt;li&gt;install requirements depends on raspberry or mac -&amp;gt; pip3 install -r requirements_raspberry.txt&lt;/li&gt;&lt;li&gt;run application -&amp;gt; python3 tensorflow_infer.py — img-mode 0 — video-path 0&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;Example image catch from running raspberry video webcam.&lt;/p&gt;
&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/640/1*BvwfD4M8xXXOU8D7M-Y5AA.jpeg&quot; /&gt;&lt;/figure&gt;
&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/640/1*gwEfwyOI-Q_3ssPJz-eF7w.jpeg&quot; /&gt;&lt;/figure&gt;
&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/640/1*9HoKRfZQxqAx2p128U1WeQ.jpeg&quot; /&gt;&lt;figcaption&gt;People which using masked unproperly or not using mask. Capture with confidence score&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;See repository on &lt;a href=&quot;https://github.com/kusumandaru/FaceMaskDetection&quot;&gt;https://github.com/kusumandaru/FaceMaskDetection&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=d0ebd2958220&quot; width=&quot;1&quot; height=&quot;1&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Sat, 25 Jul 2020 00:00:00 +0700</pubDate>
        <link>https://kusumandaru.com/mask-detector-u/</link>
        <guid isPermaLink="true">https://kusumandaru.com/mask-detector-u/</guid>
        
        
        <category>face-mask</category>
        
        <category>macbook</category>
        
        <category>tensorflow</category>
        
        <category>machine-learning</category>
        
        <category>raspberry-pi</category>
        
      </item>
    
      <item>
        <title>Create Dashcam with object detection using Raspberry Pi 4 and Tensorflow Lite</title>
        <description>&lt;p&gt;Using live detection object with tensorflow and record it on video format with common usb web, make your own dashcam.&lt;/p&gt;
&lt;p&gt;These tutorial combined from &lt;a href=&quot;https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/blob/master/Raspberry_Pi_Guide.md&quot;&gt;EdjeElectronics&lt;/a&gt; article how to build model and run on raspberry Pi, and combined with &lt;a href=&quot;https://www.pyimagesearch.com/2016/02/22/writing-to-video-with-opencv/&quot;&gt;pyimagesearch&lt;/a&gt; tutorial to save video&lt;/p&gt;
&lt;p&gt;In Indonesia, you can bought equipment here:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://www.tokopedia.com/rajacell/kamera-usb-camera-8mp-untuk-raspberry-pi-3-model-b-kabel-tarik-retrack&quot;&gt;Cheap webcam camera&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://www.bukalapak.com/p/komputer/mini-pc/3dyw77y-jual-raspberry-pi-4-model-b-ram-8-gb-siap-pakai?product_sku=7399366470&quot;&gt;Raspberry Pi 4 Complete&lt;/a&gt;, it is already include case, memory card, and power cable, since it using dash cam, try to get usb cable.&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://www.tokopedia.com/rajacell/3pcs-black-aluminium-heatsink-pendingin-heat-sink-raspberry-pi-4-b-3b&quot;&gt;Heatsink&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://www.tokopedia.com/rajacell/wireless-mini-keyboard-rii-mini-i8-2-4g-touchpad-remote-support-raspi-hitam&quot;&gt;Keyboard wireless&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/592/1*_XQ4NC8x7BeEI1B5siu2ig@2x.jpeg&quot; /&gt;&lt;/figure&gt;
&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/640/1*PaPulXEIrpI9n66ZLEtoGw@2x.jpeg&quot; /&gt;&lt;/figure&gt;
&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/288/1*IMgklPSbLQSlqMvfcfXPaQ@2x.jpeg&quot; /&gt;&lt;/figure&gt;
&lt;p&gt;Assembly raspberry with memory card, (optional) 3.5 screen and case.&lt;/p&gt;
&lt;p&gt;Connect raspberry into monitor using hdmi. Or install VNC server to remote access using laptop.&lt;/p&gt;
&lt;p&gt;Open terminal and run following steps:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;update raspberry&lt;/li&gt;&lt;/ul&gt;
&lt;pre&gt;sudo apt-get update &amp;amp;&amp;amp; sudo apt-get dist-upgrade&lt;/pre&gt;
&lt;p&gt;Connect webcam with raspberry&lt;/p&gt;
&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*WQd95dSUeP1OosNeK4zxfg@2x.jpeg&quot; /&gt;&lt;/figure&gt;
&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*AW4P9AHdCu_U68MOADth4Q@2x.jpeg&quot; /&gt;&lt;/figure&gt;
&lt;ul&gt;&lt;li&gt;install webcam driver on raspberry&lt;/li&gt;&lt;/ul&gt;
&lt;pre&gt;# install webcam driver&lt;br /&gt;sudo apt-get install fswebcam&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;check webcam work&lt;/li&gt;&lt;/ul&gt;
&lt;pre&gt;# capture image with selected resolution and set output name and format&lt;br /&gt;fswebcam -r 640x480 image.jpg&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;download code in &lt;a href=&quot;https://github.com/kusumandaru/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi&quot;&gt;github repository&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;pre&gt;# clone object&lt;br /&gt;git clone &lt;a href=&quot;https://github.com/kusumandaru/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi.git&quot;&gt;https://github.com/kusumandaru/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi.git&lt;/a&gt;&lt;/pre&gt;
&lt;pre&gt;# rename directory&lt;br /&gt;mv &lt;a href=&quot;https://github.com/kusumandaru/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi.git&quot;&gt;TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi&lt;/a&gt; tensorflow-lite-raspberry&lt;/pre&gt;
&lt;pre&gt;# go to folder&lt;br /&gt;cd tensorflow-lite-raspberry&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;create virtual environment, to separate python library to each project&lt;/li&gt;&lt;/ul&gt;
&lt;pre&gt;# install virtual environement library&lt;br /&gt;sudo pip3 install virtualenv&lt;/pre&gt;
&lt;pre&gt;# create virtual environment&lt;br /&gt;python3 -m venv tflite-env&lt;/pre&gt;
&lt;pre&gt;# activate environment&lt;br /&gt;source tflite-env/bin/activate&lt;/pre&gt;
&lt;p&gt;keep in mind to re-activate environment when reboot system.&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;install dependency&lt;/li&gt;&lt;/ul&gt;
&lt;pre&gt;bash get_pi_requirements.sh&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;Grab model&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;Google have selected model to tensorflow lite such as Image classification, object detection, and other. For these project we use object detection. When passed image it will return confidence score and location object.&lt;/p&gt;
&lt;p&gt;Confidence score: number between 0 and 1 that indicates confidence that the object was genuinely detected. The closer the number is to 1, the more confident the model is. When score is below threshold score it will abandon from result.&lt;/p&gt;
&lt;p&gt;Location: array of four numbers representing a bounding rectangle that surrounds its position consist of: top, down, left, right.&lt;/p&gt;
&lt;p&gt;Google provides a sample quantized SSDLite-MobileNet-v2 object detection model which is trained off the MSCOCO dataset and converted to run on TensorFlow Lite. It can detect and identify 80 different common objects, such as people, cars, cups, etc.&lt;/p&gt;
&lt;pre&gt;wget &lt;a href=&quot;https://storage.googleapis.com/download.tensorflow.org/models/tflite/coco_ssd_mobilenet_v1_1.0_quant_2018_06_29.zip&quot;&gt;https://storage.googleapis.com/download.tensorflow.org/models/tflite/coco_ssd_mobilenet_v1_1.0_quant_2018_06_29.zip&lt;/a&gt;&lt;/pre&gt;
&lt;pre&gt;# to get latest image download &lt;a href=&quot;https://www.tensorflow.org/lite/models/object_detection/overview&quot;&gt;https://www.tensorflow.org/lite/models/object_detection/overview&lt;/a&gt;&lt;/pre&gt;
&lt;p&gt;than extract inside tensorflow-lite-raspberrydirectory.&lt;/p&gt;
&lt;pre&gt;unzip coco_ssd_mobilenet_v1_1.0_quant_2018_06_29.zip -d tflite_model&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;running program, it need library to loaded and make sure webcam is record image, detected object will have squared boxes and label displayed in real time.&lt;/li&gt;&lt;/ul&gt;
&lt;pre&gt;python3 TFLite_detection_dashcam.py — modeldir=tflite_model&lt;/pre&gt;
&lt;p&gt;Since computational power is relative low, it only detect about 4–5 frame per second. To increase power 5–6 times, you can bought &lt;a href=&quot;https://coral.ai/products/accelerator/&quot;&gt;coral usb accelerator&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Sample video can be located below:&lt;/p&gt;
&lt;iframe src=&quot;https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fwww.youtube.com%2Fembed%2F4XVpRhM-IeM%3Ffeature%3Doembed&amp;amp;display_name=YouTube&amp;amp;url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3D4XVpRhM-IeM&amp;amp;image=https%3A%2F%2Fi.ytimg.com%2Fvi%2F4XVpRhM-IeM%2Fhqdefault.jpg&amp;amp;key=a19fcc184b9711e1b4764040d3dc5c07&amp;amp;type=text%2Fhtml&amp;amp;schema=youtube&quot; width=&quot;640&quot; height=&quot;480&quot; frameborder=&quot;0&quot; scrolling=&quot;no&quot;&gt;&lt;a href=&quot;https://medium.com/media/0e85d37b8563c800f60a82eb4fb1079e/href&quot;&gt;https://medium.com/media/0e85d37b8563c800f60a82eb4fb1079e/href&lt;/a&gt;&lt;/iframe&gt;
&lt;p&gt;&lt;img src=&quot;https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=cdec3e105e55&quot; width=&quot;1&quot; height=&quot;1&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Sat, 11 Jul 2020 00:00:00 +0700</pubDate>
        <link>https://kusumandaru.com/create-dashcam/</link>
        <guid isPermaLink="true">https://kusumandaru.com/create-dashcam/</guid>
        
        
        <category>tensorflow-lite</category>
        
        <category>raspberry-pi</category>
        
        <category>video-recognition</category>
        
        <category>video-recording</category>
        
      </item>
    
      <item>
        <title>Google Cloud Platform (GCP) Jakarta now alive</title>
        <description>&lt;p&gt;Compare pricing and function for GCP Southeast Asia&lt;/p&gt;
&lt;p&gt;For previous year, GCP asia southeast region only have Singapore as data centre, for nowadays Jakarta region is become new member of southeast. It will give privileges for Financial institution to deploy application and data center inside indonesia to comply with regulation of Personally identifiable information. Also reduce network latency rather than region outside indonesia. Jakarta now becomes one of 24 regions and 73 zones along 17 countries with served by google cloud.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Regions&lt;/em&gt; are independent geographic areas that consist of &lt;em&gt;zones&lt;/em&gt;. Locations within regions tend to have round-trip network latencies of under &amp;lt;1ms on the 95th percentile. For example jakarta located on asia-southeast2 and have 3 zone asia-southeast2-a, asia-southeast2-b, and asia-southeast2-c&lt;/p&gt;
&lt;p&gt;Jakarta region provides services such of Compute engine, Kubernetes, Cloud SQL, Cloud Spanner, BigTable and bigQuery. Hybrid customer also can have direct link via Dedicated Interconnect service.&lt;/p&gt;
&lt;p&gt;We try to compare based on these article written date (8–6–2020). Also &lt;a href=&quot;https://cloud.google.com/products/calculator&quot;&gt;google pricing calculator&lt;/a&gt; still not updated yet. TLDR; pricing is same with singapore region, so when your service running in singapore, these is great momentum to move it closer to your customer.&lt;/p&gt;
&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*Pk3Oh7iAw4esRnBg-JzPyg.png&quot; /&gt;&lt;figcaption&gt;Jakarta Region&lt;/figcaption&gt;&lt;/figure&gt;
&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*SaMSQ7eGYWEcNOqEjm547A.png&quot; /&gt;&lt;figcaption&gt;Singapore region&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Both region have same pricing schema, even for upgraded VM like second generation CPU it goes have par pricing for $60.79 each month.&lt;/p&gt;
&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/946/1*Nbzcqry24ASrDNM48nwtuw.png&quot; /&gt;&lt;figcaption&gt;OS Selection for VM&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Jakarta region also already support multiple OS&lt;br /&gt;For database it also support for PostgreSql, MySql, and SQL Server&lt;/p&gt;
&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/986/1*JHVlRLZ4rQ9Ryw1ap3Ad3g.png&quot; /&gt;&lt;figcaption&gt;support Relational Database&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;For bucket storage, google cloud storage now support for Jakarta region.&lt;/p&gt;
&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*3mZ-l6a9qkAa1JTwf2eFWg.png&quot; /&gt;&lt;figcaption&gt;Google cloud storage bucket&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;For Kubernetes it now support region and multi zone or specific zone for deploy those cluster&lt;/p&gt;
&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*aCwiQdxFLzw2tuiV1n13lw.png&quot; /&gt;&lt;figcaption&gt;Kubernetes region selection&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Unfortunately for Redis is still not supported on Indonesia&lt;/p&gt;
&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*3Jf1-w1aq63x4cbhaSKw8Q.png&quot; /&gt;&lt;figcaption&gt;redis instance&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;We also waiting Amazon Web Service to release data center in Jakarta to give head to head alternative for our as customer.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=d56318ac79cb&quot; width=&quot;1&quot; height=&quot;1&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 08 Jun 2020 00:00:00 +0700</pubDate>
        <link>https://kusumandaru.com/google-cloud-pl/</link>
        <guid isPermaLink="true">https://kusumandaru.com/google-cloud-pl/</guid>
        
        
        <category>google-cloud-platform</category>
        
        <category>indonesia</category>
        
        <category>jakarta</category>
        
        <category>gcp</category>
        
      </item>
    
      <item>
        <title>How to implement Postgre PgCrypto and migrate data to encrypted on Ruby on Rails</title>
        <description>&lt;p&gt;Secure your Personally Identifiable Information without sacrifice speed query&lt;/p&gt;
&lt;p&gt;In Ruby on Rails there is some application level encryption like &lt;a href=&quot;https://api.rubyonrails.org/v6.0.3/classes/ActiveSupport/MessageEncryptor.html&quot;&gt;MessageEncryptor&lt;/a&gt;, gemfile such as &lt;a href=&quot;https://github.com/attr-encrypted/attr_encrypted&quot;&gt;attr_encrypted&lt;/a&gt;, &lt;a href=&quot;https://github.com/ankane/lockbox&quot;&gt;lockbox&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The problem for application level encryption is tend difficult to search, eventually when your key or decryption process in cloud. There is another method to create another column and use hash computation since same value will return same hashed value.&lt;/p&gt;
&lt;p&gt;PgCrypto is module provides cryptographic functions for postgreSql, it encryption level database. It supported are both symmetric-key and public-key encryption.&lt;/p&gt;
&lt;p&gt;We try to implemented on ruby on Rails and save key into KMS platform. And migrate plain attribute into encrypted one.&lt;/p&gt;
&lt;p&gt;We install gem&lt;a href=&quot;https://github.com/stas/active_record-pgcrypto&quot;&gt; active_record-pgcrypto &lt;/a&gt;using gem install active_record-pgcrypto.&lt;/p&gt;
&lt;p&gt;Symmetric encryption encrypts and decrypts data using the same key and is faster than asymmetric encryption. It is the preferred method in an environment where exchanging secret keys is not an issue. With asymmetric encryption, a public key is used to encrypt data and a private key is used to decrypt data. This is slower then symmetric encryption and it requires a stronger key.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 1: create initializer&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;For these example, we use serializer attributes and arel API on Rails and symmetric-key encryption on postgres.&lt;/p&gt;
&lt;pre&gt;# config/initializers/pgcrypto.rb&lt;br /&gt;require &amp;#39;active_record/pgcrypto&amp;#39;&lt;br /&gt;# Replace the default environment variable name with your own value/key.&lt;br /&gt;ActiveRecord::PGCrypto::SymmetricCoder.pgcrypto_key = LOAD_FROM_KMS&lt;/pre&gt;
&lt;p&gt;We also set initializer to load symmetric key, ensure to save key outside app like using &lt;a href=&quot;https://docs.aws.amazon.com/sdk-for-ruby/v3/developer-guide/kms-examples.html&quot;&gt;AWS KMS&lt;/a&gt;, &lt;a href=&quot;https://github.com/googleapis/google-cloud-ruby/tree/master/google-cloud-kms&quot;&gt;Google KMS&lt;/a&gt;, &lt;a href=&quot;https://github.com/hashicorp/vault-ruby&quot;&gt;Vault&lt;/a&gt; or another third party key management service, to avoid breach key.&lt;/p&gt;
&lt;p&gt;For further option we can also set options and encoding via:&lt;/p&gt;
&lt;pre&gt;ActiveRecord::PGCrypto::SymmetricCoder.pgcrypto_options = &amp;#39;cipher-algo=aes256, unicode-mode=1&amp;#39;&lt;br /&gt;ActiveRecord::PGCrypto::SymmetricCoder.pgcrypto_encoding = &amp;#39;utf8&amp;#39;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Step 2: Implement model&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;On model we set serializer on rails and create function to search:&lt;/p&gt;
&lt;pre&gt;class MyModel &amp;lt; ActiveRecord::Base&lt;br /&gt;  serialize(:email, ActiveRecord::PGCrypto::SymmetricCoder)&lt;br /&gt;&lt;br /&gt;  def self.decrypted_email&lt;br /&gt;    ActiveRecord::PGCrypto::SymmetricCoder&lt;br /&gt;      .decrypted_arel_text(arel_table[:email])&lt;br /&gt;  end&lt;br /&gt;end&lt;/pre&gt;
&lt;p&gt;But since above implementation is redundant and attribute to encrypted is more than one, we create metaprogramming and create concern for these one:&lt;/p&gt;
&lt;iframe src=&quot;&quot; width=&quot;0&quot; height=&quot;0&quot; frameborder=&quot;0&quot; scrolling=&quot;no&quot;&gt;&lt;a href=&quot;https://medium.com/media/0848b276775325a5d3ee5d006dfe48ea/href&quot;&gt;https://medium.com/media/0848b276775325a5d3ee5d006dfe48ea/href&lt;/a&gt;&lt;/iframe&gt;
&lt;p&gt;&lt;em&gt;decrypted_#{attribute}&lt;/em&gt; on above method will return arel query like below&lt;/p&gt;
&lt;pre&gt;# return Arel::Nodes::NamedFunction, it can use like Arel::Nodes::Matches&lt;/pre&gt;
&lt;pre&gt;# example User.where(User.decrypted_email.matches(&amp;#39;raisa@random.com&amp;#39;))&lt;/pre&gt;
&lt;pre&gt;----- will return -----&lt;/pre&gt;
&lt;pre&gt;&amp;quot;SELECT \&amp;quot;users\&amp;quot;.* FROM \&amp;quot;users\&amp;quot; WHERE ENCODE(PGP_SYM_DECRYPT_BYTEA(\&amp;quot;users\&amp;quot;.\&amp;quot;email\&amp;quot;, CRYPTOGRAPHY_KEY), &amp;#39;escape&amp;#39;)ILIKE &amp;#39;raisa@random.com&amp;#39;&amp;quot;&lt;/pre&gt;
&lt;pre&gt;or it can use below method to get single record&lt;/pre&gt;
&lt;pre&gt;Admin.find_by(Admin.decrypted_email.eq(&amp;#39;&lt;a href=&quot;mailto:raisa@random.com&quot;&gt;raisa@random.com&lt;/a&gt;&amp;#39;))&lt;/pre&gt;
&lt;p&gt;We need to test those concern with shared_examples&lt;/p&gt;
&lt;p&gt;We try to create shared example to test model which have these function&lt;/p&gt;
&lt;iframe src=&quot;&quot; width=&quot;0&quot; height=&quot;0&quot; frameborder=&quot;0&quot; scrolling=&quot;no&quot;&gt;&lt;a href=&quot;https://medium.com/media/7c793ef8f560ea52b4f4d35e9612bb66/href&quot;&gt;https://medium.com/media/7c793ef8f560ea52b4f4d35e9612bb66/href&lt;/a&gt;&lt;/iframe&gt;
&lt;p&gt;After that we refactor previous model to become:&lt;/p&gt;
&lt;pre&gt;class MyModel &amp;lt; ActiveRecord::Base&lt;br /&gt;  include PgCryptoable&lt;/pre&gt;
&lt;pre&gt;  attr_pgcrypto :email, :full_name, :gender&lt;br /&gt;end&lt;/pre&gt;
&lt;p&gt;and adding additional test:&lt;/p&gt;
&lt;pre&gt;it_behaves_like &amp;#39;pgcryptoable model&amp;#39;&lt;/pre&gt;
&lt;pre&gt;is_expected.to have_pgcryptoable_attribute(:email)&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Step 3: migrate plain attributes&lt;/strong&gt;&lt;/p&gt;
&lt;iframe src=&quot;&quot; width=&quot;0&quot; height=&quot;0&quot; frameborder=&quot;0&quot; scrolling=&quot;no&quot;&gt;&lt;a href=&quot;https://medium.com/media/3d41a7261632058728564fc24aec620c/href&quot;&gt;https://medium.com/media/3d41a7261632058728564fc24aec620c/href&lt;/a&gt;&lt;/iframe&gt;
&lt;p&gt;On these step we enable extension pgcrypto on postgres using command enable_extension .&lt;/p&gt;
&lt;p&gt;After that we rename recent attribute into temporary field and do migration, when update method called, it will called serializer to encrypt data&lt;/p&gt;
&lt;p&gt;Thats all and now database is encrypted and query search not decrease significanly&lt;/p&gt;
&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*peAFMehWOcN12Y9xsTVQ0Q.png&quot; /&gt;&lt;figcaption&gt;time consume&lt;/figcaption&gt;&lt;/figure&gt;
&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/0*WXLKCD2VvwnaL3ET&quot; /&gt;&lt;figcaption&gt;Photo by &lt;a href=&quot;https://unsplash.com/@maurosbicego?utm_source=medium&amp;amp;utm_medium=referral&quot;&gt;Mauro Sbicego&lt;/a&gt; on &lt;a href=&quot;https://unsplash.com?utm_source=medium&amp;amp;utm_medium=referral&quot;&gt;Unsplash&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&quot;https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=e09ddbce53eb&quot; width=&quot;1&quot; height=&quot;1&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Sat, 16 May 2020 00:00:00 +0700</pubDate>
        <link>https://kusumandaru.com/how-to-implemen/</link>
        <guid isPermaLink="true">https://kusumandaru.com/how-to-implemen/</guid>
        
        
        <category>rails</category>
        
        <category>encryption</category>
        
        <category>postgres</category>
        
      </item>
    
      <item>
        <title>Encrypt decrypt Rails attribute using MessageEncryptor</title>
        <description>&lt;p&gt;How we secure sensitive data using Rails MessageEncryptor, from plain attributes to secured one.&lt;/p&gt;
&lt;p&gt;This article combined from &lt;a href=&quot;https://security.stackexchange.com/questions/17421/how-to-store-salt&quot;&gt;store salt beside hashed attributes&lt;/a&gt; and article from Pawel urbanek about &lt;a href=&quot;https://pawelurbanek.com/rails-secure-encrypt-decrypt&quot;&gt;message encryptor&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For this example each salt is located in same record encrypted attribute. It use a salt ‘works’ by making sure the hash result unique to each used instance. This is done by picking a different random salt value for each computed hash.&lt;/p&gt;
&lt;p&gt;MessageEncryptor is rails function which have ability to encrypt decrypt value use base64 encoded. It using key which generate from combination password , salt and length . For now it use ActiveSupport::MessageEncryptor.key_len which have 32 since ruby from version 2.4.0 forward use open ssl which have 32 bytes length.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Service to encrypt and decrypt&lt;/strong&gt;&lt;/p&gt;
&lt;iframe src=&quot;&quot; width=&quot;0&quot; height=&quot;0&quot; frameborder=&quot;0&quot; scrolling=&quot;no&quot;&gt;&lt;a href=&quot;https://medium.com/media/d6f122d5d193a27bbed5ad081b25b089/href&quot;&gt;https://medium.com/media/d6f122d5d193a27bbed5ad081b25b089/href&lt;/a&gt;&lt;/iframe&gt;
&lt;p&gt;It define initialise, so each new method will create encryptor/decryptor based on salt record. Then it can encrypt or decrypt attribute.&lt;/p&gt;
&lt;p&gt;It read key ENCRYPT_KEY_BASE from environment variable, make sure key not uploaded to repository and try to make unique for production and staging environment. Also create using hard random key like SecureRandom.base64 or SecureRandom.random_bytes&lt;/p&gt;
&lt;h4&gt;Define concern&lt;/h4&gt;
&lt;iframe src=&quot;&quot; width=&quot;0&quot; height=&quot;0&quot; frameborder=&quot;0&quot; scrolling=&quot;no&quot;&gt;&lt;a href=&quot;https://medium.com/media/43d81d7c0e8f31943d5127e8f9767ea8/href&quot;&gt;https://medium.com/media/43d81d7c0e8f31943d5127e8f9767ea8/href&lt;/a&gt;&lt;/iframe&gt;
&lt;p&gt;We use meta programming ruby to override class method attr_encrypted for each attribute which assigned and and assign value to encrypted_attribute&lt;/p&gt;
&lt;p&gt;Example: attr_encrypted :mother_name, on_model user, it will overriding attribute mother_name with decrypted value and reassign value for attribute encrypted_mother_name with encrypted value. You can assign multiple attribute also on these class method&lt;/p&gt;
&lt;p&gt;It send salt from record and encrypted_attribute to encryption service, either to encrypt or decrypt data.&lt;/p&gt;
&lt;p&gt;When salt not exist on those record, it also built automatically use ActiveActiveSupport::MessageEncryptor.key_len a.k.a SecureRandom.random_bytes(32)&lt;/p&gt;
&lt;h4&gt;Migrate plain attributes to encrypted one&lt;/h4&gt;
&lt;iframe src=&quot;&quot; width=&quot;0&quot; height=&quot;0&quot; frameborder=&quot;0&quot; scrolling=&quot;no&quot;&gt;&lt;a href=&quot;https://medium.com/media/cdb827fc2e5fa504290aeb18c37928c5/href&quot;&gt;https://medium.com/media/cdb827fc2e5fa504290aeb18c37928c5/href&lt;/a&gt;&lt;/iframe&gt;
&lt;p&gt;After service and model already done we try to migrate unencrypted data, we define new column with prefix encrypted_ and we add salt with type binary, in postgres it will save with format bytea. Cause salt cannot save in format string.&lt;/p&gt;
&lt;p&gt;We also define user.mother_name = user.mother_name_was since method mother_name already override on above concern, and mother_name_was is directly call active record.&lt;/p&gt;
&lt;p&gt;For better security try to store salt in different source. Like different database, or access by another endpoint, so when database was breach, key is on another world.&lt;/p&gt;
&lt;p&gt;Alternatively you can use third party cryptography service like aws/google cloud KMS, vault, or thales.&lt;/p&gt;
&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/640/1*Ze_S6uRvYBZLQxS4xBysHg.jpeg&quot; /&gt;&lt;figcaption&gt;&lt;a href=&quot;https://unsplash.com/photos/0Yiy0XajJHQ&quot;&gt;https://unsplash.com/photos/0Yiy0XajJHQ&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&quot;https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=85e10dfe90d7&quot; width=&quot;1&quot; height=&quot;1&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Sat, 02 May 2020 00:00:00 +0700</pubDate>
        <link>https://kusumandaru.com/encrypt-decrypt/</link>
        <guid isPermaLink="true">https://kusumandaru.com/encrypt-decrypt/</guid>
        
        
        <category>encryption</category>
        
        <category>rails</category>
        
        <category>salt</category>
        
      </item>
    
      <item>
        <title>Streaming json data to Big Query using Rails 6</title>
        <description>&lt;p&gt;&lt;strong&gt;How to stream data using job and test it using RSpec.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Bigquery is SAAS using REST api to managed data warehouse which provided by google. It can be combine with mapreduce and have machine learning capability.&lt;/p&gt;
&lt;p&gt;This topic is try to send data to bigQuery, there is any way to send data using ruby, such as:&lt;/p&gt;
&lt;pre&gt;# upload using csv&lt;br /&gt;table.load &amp;quot;gs://my-bucket/file-name.csv&amp;quot;&lt;/pre&gt;
&lt;pre&gt;# load using json&lt;br /&gt;table.insert data_rows&lt;/pre&gt;
&lt;p&gt;For these tutorial we try to send via last one (streaming json), for complete description see &lt;a href=&quot;https://googleapis.dev/ruby/google-cloud-bigquery/latest/index.html&quot;&gt;this link&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 1: Create service account and install gemfile&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;It assume you already install Rails 6. First of all make sure some of gem below are already insert in Gemfile.lock. rspec and webmock used for test bigquery service&lt;/p&gt;
&lt;pre&gt;gem &amp;#39;google-cloud-bigquery&amp;#39;group :test do&lt;br /&gt;  gem &amp;#39;rspec-rails&amp;#39;&lt;br /&gt;  gem &amp;#39;webmock&amp;#39;end&lt;/pre&gt;
&lt;pre&gt;end&lt;/pre&gt;
&lt;p&gt;After that, install with command bundle install .&lt;/p&gt;
&lt;p&gt;These gem using key from Service Account, before we create key, we need to define Role for these service account, since we only need to steam data and avoid alter or delete table, we register these roles:&lt;/p&gt;
&lt;iframe src=&quot;&quot; width=&quot;0&quot; height=&quot;0&quot; frameborder=&quot;0&quot; scrolling=&quot;no&quot;&gt;&lt;a href=&quot;https://medium.com/media/74ec259e9bea87810300e07e83d1caef/href&quot;&gt;https://medium.com/media/74ec259e9bea87810300e07e83d1caef/href&lt;/a&gt;&lt;/iframe&gt;
&lt;p&gt;Example give this roles name BigQuery Stream&lt;/p&gt;
&lt;p&gt;Back into service account create new one, than assign role into this service,&lt;/p&gt;
&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/0*EcHLUnNNl_2SwKkJ.png&quot; /&gt;&lt;figcaption&gt;service account generation&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Choose json file for key generation, save into local computer. (Securing these file, and never put these file on repository)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 2: Create service for stream account&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Set environment variable on for path and project_id, also make sure credential json file not on same project, so it not accidentally push on repository.&lt;/p&gt;
&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/0*008l5QIKVFsRJEg3.png&quot; /&gt;&lt;figcaption&gt;project ID&lt;/figcaption&gt;&lt;/figure&gt;
&lt;pre&gt;BIGQUERY_CREDENTIAL_PATH=/path-to-file/bigquery.json&lt;br /&gt;BIGQUERY_PROJECT_ID=bigquery-test-270003&lt;/pre&gt;
&lt;p&gt;After that create base service file to connect to bigquery, like base.rb&lt;/p&gt;
&lt;iframe src=&quot;&quot; width=&quot;0&quot; height=&quot;0&quot; frameborder=&quot;0&quot; scrolling=&quot;no&quot;&gt;&lt;a href=&quot;https://medium.com/media/e2718b7ccebeae01e758d23699e5b5a2/href&quot;&gt;https://medium.com/media/e2718b7ccebeae01e758d23699e5b5a2/href&lt;/a&gt;&lt;/iframe&gt;
&lt;p&gt;We load library bigquery also use active model for catch error on header filer&lt;/p&gt;
&lt;p&gt;We load configuration using environment variable and initialize instance on initialise method.&lt;/p&gt;
&lt;p&gt;Since we make base class as superclass and inheritance dataset and table id we must define on base.rb and than we load these dataset and table, after that we call method to send json data into bigquery.&lt;/p&gt;
&lt;p&gt;We need check if table is exist on bigquery before we stream data, and than we send data into bigquery and check if response is success or not, if response file than we catch errors to show to user and return false value, otherwise we return true response.&lt;/p&gt;
&lt;p&gt;Than we can define subclass for sent data, for example, we try send user model&lt;/p&gt;
&lt;iframe src=&quot;&quot; width=&quot;0&quot; height=&quot;0&quot; frameborder=&quot;0&quot; scrolling=&quot;no&quot;&gt;&lt;a href=&quot;https://medium.com/media/f593ba8e2688475d92c0fada3c821e8d/href&quot;&gt;https://medium.com/media/f593ba8e2688475d92c0fada3c821e8d/href&lt;/a&gt;&lt;/iframe&gt;
&lt;p&gt;We then define DATASET_ID and TABLE_ID for these service and convert model into json using as_json method&lt;/p&gt;
&lt;p&gt;we define shared example to mock bigquery, catch response form response and define on json for each request&lt;/p&gt;
&lt;iframe src=&quot;&quot; width=&quot;0&quot; height=&quot;0&quot; frameborder=&quot;0&quot; scrolling=&quot;no&quot;&gt;&lt;a href=&quot;https://medium.com/media/784244e3a72257afa198ae161bb14030/href&quot;&gt;https://medium.com/media/784244e3a72257afa198ae161bb14030/href&lt;/a&gt;&lt;/iframe&gt;
&lt;p&gt;and we create spec by test this class:&lt;/p&gt;
&lt;iframe src=&quot;&quot; width=&quot;0&quot; height=&quot;0&quot; frameborder=&quot;0&quot; scrolling=&quot;no&quot;&gt;&lt;a href=&quot;https://medium.com/media/dad452302be6d75066db8ca40709aab9/href&quot;&gt;https://medium.com/media/dad452302be6d75066db8ca40709aab9/href&lt;/a&gt;&lt;/iframe&gt;
&lt;p&gt;For final step we create job so, streaming data running on background task&lt;/p&gt;
&lt;iframe src=&quot;&quot; width=&quot;0&quot; height=&quot;0&quot; frameborder=&quot;0&quot; scrolling=&quot;no&quot;&gt;&lt;a href=&quot;https://medium.com/media/f9a89d3198aef6b74687b416190f1936/href&quot;&gt;https://medium.com/media/f9a89d3198aef6b74687b416190f1936/href&lt;/a&gt;&lt;/iframe&gt;
&lt;p&gt;We check model is exist before we send and we call service to run job&lt;/p&gt;
&lt;p&gt;for spec test we check using these command&lt;/p&gt;
&lt;iframe src=&quot;&quot; width=&quot;0&quot; height=&quot;0&quot; frameborder=&quot;0&quot; scrolling=&quot;no&quot;&gt;&lt;a href=&quot;https://medium.com/media/f44bb47ef4cc88e3f28004f72058a0a0/href&quot;&gt;https://medium.com/media/f44bb47ef4cc88e3f28004f72058a0a0/href&lt;/a&gt;&lt;/iframe&gt;
&lt;p&gt;And you can call by using command:&lt;/p&gt;
&lt;p&gt;BigQuery::UserStreamJob.perform_later(some_user.id)&lt;/p&gt;
&lt;p&gt;Check on bigquery console when data is succesfully inserted&lt;/p&gt;
&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/0*a-7b53oaGAZ58qAh.png&quot; /&gt;&lt;figcaption&gt;user table&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&quot;https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=c422ac47d520&quot; width=&quot;1&quot; height=&quot;1&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Sat, 14 Mar 2020 00:00:00 +0700</pubDate>
        <link>https://kusumandaru.com/streaming-json/</link>
        <guid isPermaLink="true">https://kusumandaru.com/streaming-json/</guid>
        
        
        <category>rails</category>
        
        <category>streaming</category>
        
        <category>bigquery</category>
        
      </item>
    
      <item>
        <title>Memetik ilmu dari pemogram senior</title>
        <description>&lt;p&gt;Apa yang dapat dipelajari dari maestro perangkat lunak dari bermacam perusahaan mulai dari IT konsultan, startup hingga perusahaan konvensional.&lt;/p&gt;
&lt;p&gt;Saya bersyukur memiliki pengalaman untuk bekerja bersama para ahli IT di berbagai macam bidang. Ini merupakan rangkuman dari hal-hal baik yang dibagikan kepada kami.&lt;/p&gt;
&lt;h3&gt;Softskill&lt;/h3&gt;
&lt;h4&gt;&lt;strong&gt;Rela untuk terus belajar&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;Di ranah IT teknologi terus bergerak dengan cepat, selain itu metodologi baru akan terus dikembangkan dan diperbarui semisal xtreme programming, agile, scrum. Bahkan pada bahasa yang sama semisal PHP niscaya terus bergerak versi serta frameworknya. Untuk itu kita harus senantiasa mengikuti perkembangan teknologi dan dapat membandingkannya apakah sesuai dengan kebutuhan. Namun di sisi lainnya tidak asal mengikuti tren masal (hype driven design) di seminar atau forum online tanpa melakukan analisis kelayakan.&lt;/p&gt;
&lt;p&gt;Harus ada keseimbangan berapa persen kecocokan teknologi yang digunakan dengan kebutuhan bisnis, selain itu dipertimbangkan pula kemudahan merekrut tim sesuai kondisi pasar bila ada pertimbangan untuk bertumbuh dengan cepat. Serta tidak kalah penting bagaimana dukungan layanan serta komunitas yang matang untuk jangka panjangnya.&lt;/p&gt;
&lt;p&gt;Poin lainnya, kita juga harus dapat mendengar pendapat tim kita tentang pemikirannya dalam mendesain atau memilih pendekatan bagaimana sistem dibuat sebelum melakukan koding untuk dapat melihat perspektif secara luas dan membantu kita menemukan celah bug yang mungkin tidak kita pikirkan sebelumnya.&lt;/p&gt;
&lt;h4&gt;Rela untuk berbagi&lt;/h4&gt;
&lt;p&gt;Terkadang kita takut kalau kita menjelaskan kode yang kita buat maka kita tidak mempunyai &lt;em&gt;bargain &lt;/em&gt;untuk bertahan atau kata lain kita menjadi mudah tergantikan. Tapi dengan kita membagi konsep kita, ada nilai positif didalamnya. Pertama ketika kita liburan, kita tidak terganggu apabila ada bug sebab ada yang bisa menindaklanjuti. Kedua ketika kita berbagi kode yang kita buat, kita tertantang untuk mengerti basis kode yang kita buat serta menambah pemahaman kita sendiri dan memperoleh masukan yang lebih baik.&lt;/p&gt;
&lt;h4&gt;Menjaga integritas&lt;/h4&gt;
&lt;p&gt;Di indonesia untuk bidang IT saat ini, seringkali kita bekerja sama atau menemui rekan kerja yang itu itu saja. Elo lagi elo lagi kasarannya. Dan ketika kita pindah kerja ternyata kita punya kenalan dengan kolega yang sama atau setidaknya memiliki info si A seperti apa atau si B direkomendasikan bagus oleh banyak pihak. Sehingga nama baik dan relasi dalam dunia IT patut dijaga dalam bentuk integritas.&lt;/p&gt;
&lt;p&gt;Referensi seringkali juga menjadi poin tambahan ketika ada perekrutan kerja. Apalagi ketika lowongan itu bersifat close recruitment atau tertutup.&lt;/p&gt;
&lt;p&gt;Menjaga nama baik itu penting sebab dunia IT itu sempit&lt;/p&gt;
&lt;h4&gt;Menempatkan situasi sesuai tempatnya&lt;/h4&gt;
&lt;p&gt;Biarkan masalah ada yang di rumah tetap di rumah dan masalah di kantor tetap di kantor. Ini diluar kasus khusus semisal ada keluarga sakit atau berduka maka kita gunakan ijin kantor untuk fokus menanganinya. Sementara apabila kita berada pada jam kantor sebaiknya urusan personal dapat dikesampingkan karena salah satu amanah adalah menghabiskan jam kerja untuk urusan kerja.&lt;/p&gt;
&lt;p&gt;Kalau kita kerja untuk keluarga, sepatutnya bila sudah di rumah kita dapat menghargai waktu untuk keluarga secara adil. Sebab kerjaan itu pasti selalu ada.&lt;/p&gt;
&lt;p&gt;Jangan sampai cuti liburan masih membawa laptop atau membalas email.&lt;/p&gt;
&lt;h4&gt;Menjaga kesehatan&lt;/h4&gt;
&lt;p&gt;Membuat aplikasi bukan kontes lari sprint untuk beberapa hari atau minggu namun merupakan buah dari perjuangan maraton bulanan hingga tahunan usaha dan perjuangan tim.&lt;/p&gt;
&lt;p&gt;Kebanyakan lembur malah akan &lt;a href=&quot;https://lengstorf.com/overtime-hurts-productivity/&quot;&gt;mengurangi produktivitas&lt;/a&gt; dalam jangka panjang.&lt;/p&gt;
&lt;p&gt;Kegiatan kecil seperti peregangan otot, jalan kecil dan minum air putih secara sering dapat mengurangi efek negatif kebanyakan duduk. Selain itu usahakan posisi mata sejajar monitor dan kurangi menunduk agar leher tidak sakit.&lt;/p&gt;
&lt;h3&gt;Hardskill&lt;/h3&gt;
&lt;h4&gt;Penamaan variable&lt;/h4&gt;
&lt;p&gt;Pernahkan saat kita akan memperbaiki bug dan menemukan kode tersebut acak adut atau tidak jelas fungsinya apa, sehingga kita jengkel dan ketika melakukan git blame ternyata penulisnya adalah kita sendiri.&lt;/p&gt;
&lt;p&gt;Penamaan variable sebisa mungkin bersifat eksplisit, jelas dan ringkas untuk apa variable itu digunakan. semisal sendSms hanya untuk mengirim sms, atau close_session untuk mengakhiri sesi yang dilakukan.&lt;/p&gt;
&lt;p&gt;Selain itu penamaan variable sebisa mungkin tidak melampui fungsi didalamnya semisal sendSms ternyata juga melakukan pengiriman notifikasi pada &lt;em&gt;fcm&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Penamaan yang spesifik juga membantu dalam pengkategorian test. Contoh apabila ada nama variable save_all , bisa terjadi ambiguitas atau pertanyaan susulan, fungsi yang disimpan itu model mana saja atau transaksi yang terjadi didalamnya apa saja. Apabila dipecah menjadi fungsi lebih kecil akan memudahkan batasan test atau cara mengetes variable ini.&lt;/p&gt;
&lt;p&gt;Terkecuali untuk transaksi yang bersifat atomik, semisal ketika melakukan debet akun, akun kreditnya juga harus ikut berubah.&lt;/p&gt;
&lt;h4&gt;Dokumentasi teknis&lt;/h4&gt;
&lt;p&gt;Dokumentasi teknis lebih baik berada dalam bentuk repository dibanding dokumen terpisah (kecuali high level documentation atau memang perjanjian dengan klien yang membutuhkan dokumentasi tertulis).&lt;/p&gt;
&lt;p&gt;Alasan kenapa dokumentasi berada pada repository (commit message), sebab kode seringkali berubah sesuai kebutuhan di lapangan, dan seringkali dokumentasi yang terpisah jarang untuk diupdate.&lt;/p&gt;
&lt;p&gt;Sebisa mungkin untuk commit message beri penjelasan singkat kenapa kode berubah dan kelompokkan berdasar kode yang berubah. Jangan melakukan 1 commit message untuk 100 kode yang berubah. selain membuat rancu dokumentasi ini juga lebih susah untuk direvert apabila ada kode yang ingin di rollback.&lt;/p&gt;
&lt;p&gt;Untuk kode yang memerlukan api, bisa menggunakan &lt;a href=&quot;https://swagger.io/&quot;&gt;swagger&lt;/a&gt; untuk dokumentasi input, output maupun test api didalamnya.&lt;/p&gt;
&lt;p&gt;Untuk dokumentasi di dalam kode masukkan apabila ada aturan bisnis yang diperlukan mengapa kode itu perlu dibuat dan tidak semua fungsi perlu didokumentasikan asal penamaan kode jelas dan fungsi bersifat terbatas bukan kode sapu jagad.&lt;/p&gt;
&lt;p&gt;Anda dapat melihat pendokumentasian teknis &lt;a href=&quot;https://medium.com/@kusumandaru/aplikasi-lebih-dari-dokumentasi-tepatkah-353c814ccd6e&quot;&gt;disini&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;TLDR anggap apa yang kita dokumentasikan ini menjadi petunjuk apabila ada developer baru itu masuk sehingga mengerti apa yang kita kerjakan.&lt;/p&gt;
&lt;h4&gt;Kode review&lt;/h4&gt;
&lt;p&gt;Kode review memberi aspek positif bagi reviewer dan pembuat &lt;em&gt;request&lt;/em&gt;. Pembuat &lt;em&gt;request&lt;/em&gt; dapat mendapat masukan bagaimana kode yang bekerja lebih efisien atau menghilangkan bug yang kasat mata. Bagi &lt;em&gt;reviewer&lt;/em&gt; ia mendapat ilmu bagaimana tugas yang diberikan diterjemahkan dalam bentuk kode, fungsi baru yang diperkenalkan oleh pembuat request. Dan menjadi prasarana untuk &lt;em&gt;transfer knowledge&lt;/em&gt; berbagi pengetahuan mengenai apa yang dikerjakan dan standar kode yang berlaku dalam organisasi tersebut.&lt;/p&gt;
&lt;p&gt;Tips untuk kode review, sebisa mungkin jangan melakukan &lt;em&gt;blaming&lt;/em&gt; tapi tanyakan pertanyaan secara konstruktif semisal:&lt;/p&gt;
&lt;p&gt;Kalau fungsi ini dipisah ke beberapa fungsi kecil ini akan lebih mudah dibaca dan di-maintenance. &lt;strong&gt;&lt;em&gt;dibanding&lt;/em&gt;&lt;/strong&gt;&lt;em&gt; &lt;/em&gt;Kenapa fungsi ini punya 100 baris kode?&lt;/p&gt;
&lt;p&gt;Untuk pull request sebisa mungkin dipecah ke satuan task, sehingga pull request tidak terlalu besar dan menyebabkan reviewer menjadi pusing dan malas untuk mereview puluhan hingga ratusan perubahan file.&lt;/p&gt;
&lt;p&gt;Apabila dirasa perubahan kode tidak bisa di masukkan ke &lt;em&gt;branch master&lt;/em&gt; secara sedikit, coba buat feature branchyang berasal dari master atau lakukan feature flag untuk kode tersebut tidak langsung aktif ketika di&lt;em&gt;merge&lt;/em&gt; ke master.&lt;/p&gt;
&lt;p&gt;Selain itu jangan baper di pull request, dan merasa ditekan. Ingat konflik hanya ada di atas komentar, tidak ada &lt;em&gt;personal feeling&lt;/em&gt; di dalamnya.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;Melakukan test&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;Ada dua tipe test yang setidaknya dibuat sebagai perekayasa perangkat lunak.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Unit test&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Unit test merupakan unit terkecil pengecekan kode yang dibuat berdasar fungsi tiap kelas. 1 kelas unit test bertanggung jawab untuk mengecek 1 kelas yang ada.&lt;/p&gt;
&lt;p&gt;Setidaknya ada 3 pengecekan yang dilakukan pada unit test:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;test yang dilakukan agar response berjalan sesuai dengan keinginan kita&lt;/li&gt;&lt;li&gt;test yang dilakukan agar error ditemukan (predictable error)&lt;/li&gt;&lt;li&gt;test yang dilakukan apabila input program tidak sesuai&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Integration test / system testing&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Tes ini dilakukan untuk menerjemahkan kebutuhan bisnis apakah sesuai dengan kode yang kita kembangkan.&lt;/p&gt;
&lt;p&gt;Tes ini bersifat &lt;em&gt;high level&lt;/em&gt;, tes ini bersifat apakah input yang diberikan user mempengaruhi modul mana saja, servis yang dijalankan dan tidak dijalankan mana saja, apakah ada validasi di model lain rusak ketika ada inputan dimasukkan.&lt;/p&gt;
&lt;p&gt;Dan apabila ada skenario yang tidak normal, respon yang diberikan sesuai misal tidak error 500 tapi menampilkan halaman ilustrasi permintaan maaf.&lt;/p&gt;
&lt;h4&gt;Menghadapi error&lt;/h4&gt;
&lt;p&gt;Jangan kedepankan asumsi, coba lakukan beberapa pengecekan terlebih dahulu seperti.&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Apakah kode yang diproduksi merupakan kode yang paling terbaru. (bisa dilakukan dengan git logatau memasukkan versi program ketika release)&lt;/li&gt;&lt;li&gt;Apakah konfigurasi yang dijalankan pada production sudah sesuai.&lt;/li&gt;&lt;li&gt;Apakah database telah menggunakan skema yang paling baru apabila ada penambahan tabel atau kolom&lt;/li&gt;&lt;li&gt;Cek log yang terjadi apakah pesan error yang terjadi (untuk itu pastikan ketika ada error sedapat mungkin jangan dilakukan catch exception karena ini dapat mengkaburkan penyebab error yang terjadi)&lt;/li&gt;&lt;li&gt;Apabila ada sumber dayanya dan secara aturan diperbolehka. Gunakan monitoring seperti scout, new relic atau stackify. Ini akan mempermudah apabila error terjadi di production dan melakukan reka ulang kejadian.&lt;/li&gt;&lt;/ul&gt;
&lt;blockquote&gt;- sekian, murid pamit dulu untuk menimba ilmu lainnya&lt;/blockquote&gt;
&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/640/1*8Ak7RPdV2bxbU5lw-2Eing.jpeg&quot; /&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&quot;https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=d441249c5002&quot; width=&quot;1&quot; height=&quot;1&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 11 Dec 2019 00:00:00 +0700</pubDate>
        <link>https://kusumandaru.com/memetik-ilmu-da/</link>
        <guid isPermaLink="true">https://kusumandaru.com/memetik-ilmu-da/</guid>
        
        
        <category>software-development</category>
        
        <category>technology</category>
        
        <category>experience</category>
        
      </item>
    
      <item>
        <title>How to clone medium story into custom domain</title>
        <description>&lt;h3&gt;How to build custom domain medium today&lt;/h3&gt;
&lt;p&gt;Duplicate your medium content on your own site using jekyll and feedjira&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Perquisites: see article &lt;/em&gt;&lt;a href=&quot;https://medium.com/@kusumandaru/create-personal-website-on-second-152339342b7c&quot;&gt;&lt;em&gt;https://medium.com/@kusumandaru/create-personal-website-on-second-152339342b7c&lt;/em&gt;&lt;/a&gt;&lt;em&gt; to step by step detail how to set and publish site.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;As we know since November 2017 &lt;a href=&quot;https://help.medium.com/hc/en-us/articles/115003053487-Custom-Domains-service-deprecation&quot;&gt;medium&lt;/a&gt; will not accept custom domain as part of medium. How if we want to took our content from medium and move it to our personal domain with only cost custom domain in nowadays.&lt;/p&gt;
&lt;p&gt;Disclaimer: rather than publication will be hosted on Medium, it still using own hosting, i prefer github pages to hosting static page, cause it’s free and simple.&lt;/p&gt;
&lt;p&gt;First of all we need Jekyll and specific template, i use template &lt;a href=&quot;https://bootstrapstarter.com/bootstrap-templates/template-mediumish-bootstrap-jekyll/&quot;&gt;mediumish&lt;/a&gt; since it have sleek design and more relevant with medium design. It also have additional configuration for comment, google analytic and featured image.&lt;/p&gt;
&lt;p&gt;Since it using markdown file (.md) as source of article&lt;/p&gt;
&lt;pre&gt;---&lt;br /&gt;layout: post&lt;br /&gt;title:  &amp;quot;Cool title&amp;quot;&lt;br /&gt;author: angga kusumandar&lt;br /&gt;categories: [ Jekyll, tutorial ]&lt;br /&gt;image: assets/images/5.jpg&lt;br /&gt;description: &amp;quot;Something about this post here&amp;quot;&lt;br /&gt;---&lt;/pre&gt;
&lt;p&gt;we create md file from rss of medium, example &lt;a href=&quot;https://medium.com/feed/@kusumandaru&quot;&gt;https://medium.com/feed/@kusumandaru&lt;/a&gt;, we can grab it and transform into md file. Take a note if each rss have ten latest article, and it can generate new one if new article medium exist, for old article you need create md file manually.&lt;/p&gt;
&lt;pre&gt;url = &amp;quot;https://medium.com/feed/@#{username}&amp;quot;&lt;/pre&gt;
&lt;pre&gt;xml = ::HTTParty.get(url).body&lt;/pre&gt;
&lt;pre&gt;feeds = Feedjira.parse(xml)&lt;/pre&gt;
&lt;pre&gt;feeds.entries.each do |entry|&lt;/pre&gt;
&lt;pre&gt;  p &amp;quot;Title: #{entry.title}, published on Medium #{entry.url} #{entry}&amp;quot;&lt;/pre&gt;
&lt;pre&gt;  create_file(entry, site)&lt;/pre&gt;
&lt;pre&gt;end&lt;/pre&gt;
&lt;p&gt;first we try to get rss and get entries data&lt;/p&gt;
&lt;pre&gt;def image_url(content)&lt;/pre&gt;
&lt;pre&gt;  doc = Nokogiri::HTML(content)&lt;/pre&gt;
&lt;pre&gt;  doc.xpath(&amp;quot;//img&amp;quot;)[0][&amp;#39;src&amp;#39;]&lt;/pre&gt;
&lt;pre&gt;end&lt;/pre&gt;
&lt;p&gt;we also parse image using Nokogiri to get first image from each article to convert as feature image&lt;/p&gt;
&lt;pre&gt;path_file = &amp;quot;./_posts/&amp;quot; + published.strftime(&amp;#39;%F&amp;#39;) + &amp;#39;-&amp;#39; + title.parameterize.first(15) + &amp;quot;.md&amp;quot;&lt;/pre&gt;
&lt;pre&gt;path = site.in_source_dir(path_file)&lt;/pre&gt;
&lt;p&gt;and than we create file with publish data and title to make unique and sort article by date&lt;/p&gt;
&lt;pre&gt;File.open(path, &amp;#39;wb&amp;#39;) do |file|&lt;/pre&gt;
&lt;pre&gt;  file.write &amp;quot;---&amp;quot;&lt;/pre&gt;
&lt;pre&gt;  file.write &amp;quot;\n&amp;quot;&lt;/pre&gt;
&lt;pre&gt;  file.write &amp;quot;layout: post&amp;quot;&lt;/pre&gt;
&lt;pre&gt;  file.write &amp;quot;\n&amp;quot;&lt;/pre&gt;
&lt;pre&gt;  file.write &amp;quot;title: #{title}&amp;quot;&lt;/pre&gt;
&lt;pre&gt;  file.write &amp;quot;\n&amp;quot;&lt;/pre&gt;
&lt;pre&gt;  file.write &amp;quot;author: #{author}&amp;quot;&lt;/pre&gt;
&lt;pre&gt;  file.write &amp;quot;\n&amp;quot;&lt;/pre&gt;
&lt;pre&gt;  file.write &amp;quot;categories: #{category}&amp;quot;&lt;/pre&gt;
&lt;pre&gt;  file.write &amp;quot;\n&amp;quot;&lt;/pre&gt;
&lt;pre&gt;  file.write &amp;quot;image: #{image}&amp;quot;&lt;/pre&gt;
&lt;pre&gt;  file.write &amp;quot;\n&amp;quot;&lt;/pre&gt;
&lt;pre&gt;  file.write &amp;quot;---&amp;quot;&lt;/pre&gt;
&lt;pre&gt;  file.write &amp;quot;\n&amp;quot;&lt;/pre&gt;
&lt;pre&gt;  file.write content&lt;/pre&gt;
&lt;pre&gt;end&lt;/pre&gt;
&lt;p&gt;and then we create content of md file with spesific format and content&lt;/p&gt;
&lt;p&gt;After that try to publish static page using JEKYLL_ENV=production bundle exec jekyll build. also on spesific md file, add feature: true to make artice published on top of index page. Finally publish site page in github page.&lt;/p&gt;
&lt;p&gt;And voila your website now consist medium content.&lt;/p&gt;
&lt;p&gt;You can see full repository code &lt;a href=&quot;https://github.com/kusumandaru/medium-rss&quot;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*5aLb7BKRDdMgLyCCEBwE9g.png&quot; /&gt;&lt;figcaption&gt;final website&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&quot;https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=3ab1c3c9625f&quot; width=&quot;1&quot; height=&quot;1&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Sat, 21 Sep 2019 00:00:00 +0700</pubDate>
        <link>https://kusumandaru.com/how-to-clone-me/</link>
        <guid isPermaLink="true">https://kusumandaru.com/how-to-clone-me/</guid>
        
        
        <category>rss-feeds</category>
        
        <category>médium</category>
        
        <category>jekyll</category>
        
        <category>clone-data</category>
        
      </item>
    
      <item>
        <title>How we rewrite our code without customer aware and uninterrupted business</title>
        <description>&lt;h4&gt;Rebuild could be cure for startup problem on scale and bug flooding, how to make sure it become medicine rather than band aid.&lt;/h4&gt;
&lt;p&gt;When beginning project was initiated, either you are startup or stable corporation, we tend to make project which have technical debt inside. it could like: don’t have any test, bad naming variable, hard to scale, complicated to modified, took wrong short cut, or anything else which can you drink aspirin everyday to catch customer growth or make minimum viable product which accepted by market. And time is passed and now management want new feature or your customer raise into exponentially growth. Nevertheless your system is hard to adapt either your team busy on fixing never ending bug or found perplexity to adding new stuff.&lt;/p&gt;
&lt;p&gt;Suddenly your whole team (and management) agreed to do some refactor plan to overcome those obstacles. But refactor is tricky challenge, it’s hard to see progress as clear as development (some ticket seems not move day to day) and have some drawback like:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;you must allocate dedicated member and time,&lt;/li&gt;&lt;li&gt;make regressive whole testing,&lt;/li&gt;&lt;li&gt;hold some new feature,&lt;/li&gt;&lt;li&gt;make sure recent feature still steady and not broken,&lt;/li&gt;&lt;li&gt;lack of documentation how recent module work.&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;In current company we do rewrite not only make it project more robust and clean but also change language and framework, and how we roll it without customer unconsciously disturbed, let’s dive in.&lt;/p&gt;
&lt;p&gt;Our progress is start on beginning of 2018.&lt;/p&gt;
&lt;p&gt;We move from PHP to Ruby on Rails cause our CTO love ruby. kidding :)&lt;/p&gt;
&lt;p&gt;We change to ruby cause of several aspect:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;No test on phpUnit, when join, i try to make unit test on php and it long time to separate logic and query builder on current class and it spend long time to prepare input data rather than create logic test.&lt;/li&gt;&lt;li&gt;No standardisation and code review, yes this is not language sin but it make some code is have duplication (not DRY) and hard to read.&lt;/li&gt;&lt;li&gt;Hard to maintain, when you change or add new feature it tend to make other feature became broken. We pray to God when we deploy our system still fine on our patch.&lt;/li&gt;&lt;li&gt;On-the-fly calculation, in some feature, when use option Ait will read directly from database and otherwise when we use option Bit need to recalculate using some formula, it make data inconsistent on some area and make customer upset.&lt;/li&gt;&lt;li&gt;Some UI/UX need to adapt.&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;Disclaimer: i don’t say Rails is better than Laravel. We change over language because on past development developer tend to use any shortcut and we don’t want premature refactor if use same language also we need separate repository to adapt strict pipeline: like linter and running whole testing, before code merge to master branch.&lt;/p&gt;
&lt;p&gt;Strategy pattern to rewrite:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;We try replace module 1 by 1 rather than big bang deploy. Bigbang deploy can bring catastrophe like previous module, it needs long time to build among half until several years with unchanged scope, but customer demand can change in several month, also it make big scope to be underestimated on time estimation, and forget side case scenario.&lt;/li&gt;&lt;li&gt;Use data driven when adopt old module to new one, use how many transaction which generated, more transaction in selected module means important to build, use net promoter score to scan part of module to be improved.&lt;/li&gt;&lt;li&gt;We use group discussion on new database schema to analyse outcome challenge and capability of proposed database, we even invite product owner to make scenario and make simulation how data is insert and read.&lt;/li&gt;&lt;li&gt;Use pair programming to initialise core code like model definition and basic service. We do pair programming also for migration script cause it have some many if-else condition cause of abnormal data and different behaviour between old system and new system.&lt;/li&gt;&lt;li&gt;Make coverage test to more than 90%.&lt;/li&gt;&lt;li&gt;Use code review and linter to make code become standard. Also implemented on repository pipeline so every code can be tested and standardized.&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;Our first deploy is login and signup module, we use existing table to avoid migration and make as proof on concept if code can be running on production, we also use same session and oauth to make sure laravel can use login module directly.&lt;/p&gt;
&lt;p&gt;And voila it works like charm.&lt;/p&gt;
&lt;p&gt;Next step is do refactor on core data like decoupling employee information, role and additional attribute. We don’t change current column on existing table but we leverage on other table. In this step we make new table like profile to save personal identity employee, dependent to save family member and other table which become supplement of employee.&lt;/p&gt;
&lt;p&gt;And before deploy in production we found some chaotic moment cause of some unexpected thing we don’t realise. Like:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;both system need redirection url between each system.&lt;/li&gt;&lt;li&gt;Some data need to be created on old system but it not exist on new one (we create some endpoint to call old system module, to create relevant data which used by laravel)&lt;/li&gt;&lt;li&gt;some data have anomaly (inconsistent ) because in new system some validation is more strict than old one.&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;In these case we use transaction to lock data when migrate and use rollback when some error occurred, we did in staging fortunately.&lt;/p&gt;
&lt;p&gt;We do on mob programming on co-working place to avoid disturbing and to more focus (we do this about 5 days), and after that our core system replaced in new one.&lt;/p&gt;
&lt;p&gt;We monitor and fix some bugs on several day later. Before facing more challenging area, migrate rest module and shutdown php.&lt;/p&gt;
&lt;p&gt;We learn some point after last deploy like:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;It cause downtime on all customer (3 hour only in 1 module) and affected to all customer and we want avoid this on next iteration. Imagine next iteration is remaining module (12 * 3 hour downtime is bad scenario)&lt;/li&gt;&lt;li&gt;There are gap of validation on old data and new data, and since next module is write on new table, it need more test scenario to adapt and convert missing validation.&lt;/li&gt;&lt;li&gt;Some customer already churn, and we don’t hesitating to migrate this customer on new feature.&lt;/li&gt;&lt;li&gt;It need dev-ops to run migration process. We ask dev-ops to running migration and we waiting result either success and fail, and when fail we ask log to dev-ops again.&lt;/li&gt;&lt;li&gt;It one-way street and cannot turn back around when customer feels better on old system. Customer must accept it, like or not.&lt;/li&gt;&lt;li&gt;We do overtime on weekend, it deteriorate mental and make physical exhausted and can make wrong decision indeed. We want work life balance so we try to avoid this method.&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;Cause of above point we try to make migrate by selected customer rather than global (whole company). With step:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Coordinate business development and product owner to select and inform customer which want to migrate on new feature.&lt;/li&gt;&lt;li&gt;Using regression test using automate script by Software Development Engineer in Test (SDET) to match old data and new data. And when we found some anomaly in some customer, other customer still can be moved.&lt;/li&gt;&lt;li&gt;Deploy refactoring code on production but only activated on new signup customer to get direct feedback to improve.&lt;/li&gt;&lt;li&gt;Select company or some company via admin dashboard, so everyone can migrate and call web-hook to flock / slack so progress can be tracked, we also got log when it fail, some migration running on long time on background processing job.&lt;/li&gt;&lt;li&gt;Freeze whole account on selected member of company and force logout so no data change when migrate to keep data consistent.&lt;/li&gt;&lt;li&gt;Do migration on one transaction so when some bad occurred old data still save. We do on job with zero retry. It’s important to stop retry cause it cause locking database.&lt;/li&gt;
&lt;/ul&gt;
&lt;script src=&quot;https://gist.github.com/kusumandaru/8f1eb6259e49f7178a0ac3fa94e6921b.js&quot;&gt;&lt;/script&gt;

&lt;ul&gt;&lt;li&gt;Make some feature toggling so when migration done any redirection and service switch and new one. We use redis to make IO read fast.&lt;/li&gt;&lt;li&gt;Set versioning migration so we can track company status migration of each company.&lt;/li&gt;&lt;li&gt;Button to rollback when needed, to switch back to old system. So when customer still missing old system, or some new system not work, we can accommodate.&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;And before customer migration, we do some improvement like:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;automatic deploy (continuous delivery and continuous integration) so we can deploy every time code merge to production. &lt;a href=&quot;https://medium.com/sleekrco/the-journey-build-continuous-deployment-sleekr-69f07adb7efe&quot;&gt;see this link&lt;/a&gt;&lt;/li&gt;&lt;li&gt;Make code already in production but not active with feature toggle. (Deploy code on dormant mode).&lt;/li&gt;&lt;li&gt;Do scrum routine like daily standup to catch problem early, create Pull Request so everyone can understand proposed change and catch some edge case defect and make code have more quality&lt;/li&gt;&lt;/ul&gt;
&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*2jmbYRYsAY7XWW1FWJ7V8Q.jpeg&quot; /&gt;&lt;figcaption&gt;Photo by &lt;a href=&quot;https://unsplash.com/@martinirc?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText&quot;&gt;José Martín Ramírez C&lt;/a&gt; on &lt;a href=&quot;https://unsplash.com/search/photos/business?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText&quot;&gt;Unsplash&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&quot;https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=b4590273c3c9&quot; width=&quot;1&quot; height=&quot;1&quot; /&gt;&amp;lt;hr&amp;gt;&amp;lt;p&amp;gt;&lt;a href=&quot;https://medium.com/sleekrco/how-we-rewrite-our-code-without-customer-aware-and-uninterrupted-business-b4590273c3c9&quot;&gt;How we rewrite our code without customer aware and uninterrupted business&lt;/a&gt; was originally published in &lt;a href=&quot;https://medium.com/sleekrco&quot;&gt;Daily Sleekr&lt;/a&gt; on Medium, where people are continuing the conversation by highlighting and responding to this story.&amp;lt;/p&amp;gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 28 Aug 2019 00:00:00 +0700</pubDate>
        <link>https://kusumandaru.com/how-we-rewrite/</link>
        <guid isPermaLink="true">https://kusumandaru.com/how-we-rewrite/</guid>
        
        
        <category>migration</category>
        
        <category>rebuild</category>
        
        <category>continuous-integration</category>
        
        <category>startup</category>
        
      </item>
    
      <item>
        <title>Publish subscribe on ruby on rails</title>
        <description>&lt;p&gt;Using RabbitMQ bunny and sneakers&lt;/p&gt;
&lt;p&gt;This tutorial contain example how to implement service oriented architecture on ruby on rails, using RabbitMQ, bunny as producer and sneakers as consumer. This introduction accommodating step by step from first installation.&lt;/p&gt;
&lt;p&gt;I got idea from &lt;a href=&quot;https://medium.com/@himang27s/background-job-in-rails-using-rabbitmq-and-sneaker-449c07284abf&quot;&gt;this&lt;/a&gt; medium post and adding some additional step.&lt;/p&gt;
&lt;h4&gt;Initiation and environment setup&lt;/h4&gt;
&lt;p&gt;First of all, we create skeleton of rails, using command: rails new {branch_name} -d mysql, this function create basic rails file and folder and using database mysql instead default sqlite.&lt;/p&gt;
&lt;p&gt;After files are initiated, go to folder via cd {branch_name} and then type bundle to install rails dependencies. After success go to config/database.yml and set some environment variable like host, username and password.&lt;/p&gt;
&lt;pre&gt;default: &amp;amp;default  &lt;br /&gt;adapter: mysql2&lt;br /&gt;encoding: utf8  &lt;br /&gt;pool: &amp;lt;%= ENV.fetch(&amp;quot;RAILS_MAX_THREADS&amp;quot;) { 5 } %&amp;gt;  &lt;br /&gt;host: &amp;lt;%= ENV.fetch(&amp;quot;RAILS_HOST_DB&amp;quot;) %&amp;gt;  &lt;br /&gt;username: &amp;lt;%= ENV.fetch(&amp;quot;RAILS_USERNAME_DB&amp;quot;) %&amp;gt;  &lt;br /&gt;password: &amp;lt;%= ENV.fetch(&amp;quot;RAILS_PASSWORD_DB&amp;quot;) %&amp;gt;  &lt;br /&gt;socket: /tmp/mysql.sock&lt;/pre&gt;
&lt;p&gt;For development convenience i set some environment on .env and read using gem dotenv-rails, on Gemfile add gemfile &amp;#39;dotenv-rails&amp;#39; on group :development, :test section and type bundle again in terminal. After dependencies were updated, create .env file on root folder and fill like&lt;/p&gt;
&lt;pre&gt;RAILS_HOST_DB=127.0.0.1&lt;br /&gt;RAILS_USERNAME_DB=root&lt;br /&gt;RAILS_PASSWORD_DB=secret_password&lt;/pre&gt;
&lt;p&gt;also on config/application.rb add new line Dotenv::Railtie.load&lt;/p&gt;
&lt;p&gt;Do initialize database using command rails db:create , and voila now on your mysql instance, two database created.&lt;/p&gt;
&lt;p&gt;We continue to create model using command rails generate model User first_name:string last_name:string email:string , it will automatically generate model, test/model and migration file on db/migrate.&lt;/p&gt;
&lt;p&gt;Try to runrails db:migrate to create table and column on schema database.&lt;/p&gt;
&lt;p&gt;Since we try using rspec and shoulda matcher to test, we adding additional gem on test section&lt;/p&gt;
&lt;pre&gt;gem ‘rspec-rails’&lt;/pre&gt;
&lt;pre&gt;gem ‘shoulda-matchers’&lt;/pre&gt;
&lt;p&gt;and again type bundle and additional rails generate rspec:install to create spec_helper and rails_helper&lt;/p&gt;
&lt;p&gt;Finally we back to model User.rb and add simple validation like validates :first_name, :last_name, :email, presence: true to make validation of mandatory variable&lt;/p&gt;
&lt;h4&gt;Set publisher&lt;/h4&gt;
&lt;p&gt;Install rabbitMq client, one of gem is &lt;a href=&quot;https://github.com/ruby-amqp/bunny&quot;&gt;bunny&lt;/a&gt; using command:gem install bunny and set initializer. You can use initializers to hold configuration settings that should be made after all of the frameworks and plugins are loaded.&lt;/p&gt;
&lt;p&gt;create new file on config/initializers/publisher/bunny_publisher.rb than set logger and connection. for simpliest setup can be used like Bunny.new(&amp;quot;amqp://guest:guest@localhost:5672&amp;quot;) but we can also set more advance setting like :&lt;/p&gt;
&lt;pre&gt;@connection ||= begin&lt;/pre&gt;
&lt;pre&gt;  instance = Bunny.new(&lt;/pre&gt;
&lt;pre&gt;    addresses: &amp;#39;localhost:5672&amp;#39;,&lt;/pre&gt;
&lt;pre&gt;    username: &amp;#39;guest&amp;#39;,&lt;/pre&gt;
&lt;pre&gt;    password: &amp;#39;guest&amp;#39;,&lt;/pre&gt;
&lt;pre&gt;    vhost: &amp;#39;/&amp;#39;,&lt;/pre&gt;
&lt;pre&gt;    logger: Rails.logger&lt;/pre&gt;
&lt;pre&gt;  )&lt;/pre&gt;
&lt;pre&gt;  instance.start&lt;/pre&gt;
&lt;pre&gt;  instance&lt;/pre&gt;
&lt;pre&gt;end&lt;/pre&gt;
&lt;p&gt;It will create connection when not initiated before.&lt;/p&gt;
&lt;p&gt;After initializer created you can create service on app/services/user_publisher.rb , with main method publish&lt;/p&gt;
&lt;pre&gt;def publish(options = {})&lt;/pre&gt;
&lt;pre&gt;  channel = ::Publisher::BunnyPublisher.connection.create_channel&lt;/pre&gt;
&lt;pre&gt;  exchange = channel.exchange(&lt;/pre&gt;
&lt;pre&gt;    &amp;#39;sneakers&amp;#39;,&lt;/pre&gt;
&lt;pre&gt;    type: &amp;#39;direct&amp;#39;,&lt;/pre&gt;
&lt;pre&gt;    durable: true&lt;/pre&gt;
&lt;pre&gt;  )&lt;/pre&gt;
&lt;pre&gt;  headers = { &amp;#39;x-delay&amp;#39; =&amp;gt; options[:delay_time].to_i * 1_000 } if options[:delay_time].present?&lt;/pre&gt;
&lt;pre&gt;  exchange.publish(payload.to_json, routing_key: QUEUE_NAME, headers: headers)&lt;/pre&gt;
&lt;pre&gt;end&lt;/pre&gt;
&lt;p&gt;make sure queue name in publisher same with customer, than publisher ready to use.&lt;/p&gt;
&lt;h4&gt;Set consumer&lt;/h4&gt;
&lt;p&gt;For background processing consumer we choose &lt;a href=&quot;https://github.com/jondot/sneakers&quot;&gt;sneakers&lt;/a&gt;, install via gem install sneakers&lt;/p&gt;
&lt;p&gt;create initializer on config/initializers/sneakers.rb and set configuration:&lt;/p&gt;
&lt;pre&gt;Sneakers.configure  connection: Connection.sneakers,&lt;/pre&gt;
&lt;pre&gt;  exchange: &amp;#39;sneakers,&lt;/pre&gt;
&lt;pre&gt;  exchange_type: :direct,&lt;/pre&gt;
&lt;pre&gt;  runner_config_file: nil,&lt;/pre&gt;
&lt;pre&gt;  metric: nil,&lt;/pre&gt;
&lt;pre&gt;  workers: 1,&lt;/pre&gt;
&lt;pre&gt;  log: STDOUT,&lt;/pre&gt;
&lt;pre&gt;  pid_path: &amp;#39;sneakers.pid&amp;#39;,&lt;/pre&gt;
&lt;pre&gt;  timeout_job_after: 5.minutes,&lt;/pre&gt;
&lt;pre&gt;  env: ENV[&amp;#39;RAILS_ENV&amp;#39;], &lt;/pre&gt;
&lt;pre&gt;  durable: true,&lt;/pre&gt;
&lt;pre&gt;  ack: true,&lt;/pre&gt;
&lt;pre&gt;  heartbeat: 2,&lt;/pre&gt;
&lt;pre&gt;  handler: Sneakers::Handlers::Maxretry&lt;/pre&gt;
&lt;pre&gt;Sneakers.logger = Rails.logger&lt;/pre&gt;
&lt;pre&gt;Sneakers.logger.level = Logger::WARN&lt;/pre&gt;
&lt;p&gt;we choose &lt;strong&gt;ack&lt;/strong&gt; option to be true to make sure message must be acknowledge when process is finished on consumer&lt;/p&gt;
&lt;p&gt;and then we create worker on app/workers/user_create.rb&lt;/p&gt;
&lt;pre&gt;include Sneakers::Worker&lt;/pre&gt;
&lt;pre&gt;QUEUE_NAME = ::UserPublisher::QUEUE_NAME&lt;/pre&gt;
&lt;pre&gt;from_queue QUEUE_NAME, arguments: { &amp;#39;x-dead-letter-exchange&amp;#39;: &amp;quot;#{QUEUE_NAME}-retry&amp;quot; }&lt;/pre&gt;
&lt;pre&gt;def work(msg)&lt;/pre&gt;
&lt;pre&gt;  data = ActiveSupport::JSON.decode(msg)&lt;/pre&gt;
&lt;pre&gt;  data[&amp;#39;users&amp;#39;].each do |user|&lt;/pre&gt;
&lt;pre&gt;    update_user(user.to_h)&lt;/pre&gt;
&lt;pre&gt;  end&lt;/pre&gt;
&lt;pre&gt;  ack!&lt;/pre&gt;
&lt;pre&gt;rescue StandardError =&amp;gt; e&lt;/pre&gt;
&lt;pre&gt;  create_log(false, data, message: e.message)&lt;/pre&gt;
&lt;pre&gt;  reject!&lt;/pre&gt;
&lt;pre&gt;end&lt;/pre&gt;
&lt;p&gt;so on above code we get message from rabbitMq and we decode and iterate and update 1 by one, when no raise error it will call ack! to inform in RabbitMq if message already done processed&lt;/p&gt;
&lt;p&gt;now we can call consumer rake, via rake sneakers:run, make sure in ENV WORKERS=UserCreate it scan worker folders with class_name UserCreate&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Test publishing and consuming&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;To publish you can call UserPublisher and it will consumed automatically.&lt;/p&gt;
&lt;pre&gt;irb(main):002:0&amp;gt; user_params = [{id: 1, first_name: &amp;#39;first&amp;#39;}]&lt;br /&gt;=&amp;gt; [{:id=&amp;gt;1, :first_name=&amp;gt;&amp;quot;first&amp;quot;}]&lt;br /&gt;irb(main):003:0&amp;gt; UserPublisher.new(user_params).publish&lt;/pre&gt;
&lt;p&gt;on cosumer it will wait for any message&lt;/p&gt;
&lt;pre&gt;rake sneakers:run           &lt;br /&gt;&lt;br /&gt;2019-08-17T05:36:41Z p-83921 t-owt7p5uik DEBUG: [worker-user.create:1:d5ckph][#&amp;lt;Thread:0x00007fd5b0885d78 run&amp;gt;][user.create][#&amp;lt;Sneakers::Configuration:0x00007fd5b6efd240&amp;gt;] New worker: subscribing.&lt;/pre&gt;
&lt;pre&gt;2019-08-17T05:36:41Z p-83921 t-owt7p5uik DEBUG: [worker-user.create:1:d5ckph][#&amp;lt;Thread:0x00007fd5b0885d78 run&amp;gt;][user.create][#&amp;lt;Sneakers::Configuration:0x00007fd5b6efd240&amp;gt;] New worker: I&amp;#39;m alive.&lt;/pre&gt;
&lt;pre&gt;2019-08-17T05:41:03Z p-83921 t-owt7x84vw DEBUG: [worker-user.create:1:d5ckph][#&amp;lt;Thread:0x00007fd5b225af78@/Users/ndaru/.rbenv/versions/2.5.0/lib/ruby/gems/2.5.0/gems/bunny-2.14.2/lib/bunny/consumer_work_pool.rb:101 run&amp;gt;][user.create][#&amp;lt;Sneakers::Configuration:0x00007fd5b6efd240&amp;gt;] Working off: &amp;quot;{\&amp;quot;users\&amp;quot;:[{\&amp;quot;id\&amp;quot;:1,\&amp;quot;first_name\&amp;quot;:\&amp;quot;first\&amp;quot;}]}&amp;quot;&lt;/pre&gt;
&lt;p&gt;You can trace repository in &lt;a href=&quot;https://github.com/kusumandaru/rails_queue&quot;&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*23WsqANJv5IS4ar-LGU2sw.jpeg&quot; /&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&quot;https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=6aa6893ef819&quot; width=&quot;1&quot; height=&quot;1&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Sat, 17 Aug 2019 00:00:00 +0700</pubDate>
        <link>https://kusumandaru.com/publish-subscri/</link>
        <guid isPermaLink="true">https://kusumandaru.com/publish-subscri/</guid>
        
        
        <category>publish-subscribe</category>
        
        <category>ruby-on-rails</category>
        
        <category>rabbitmq</category>
        
      </item>
    
  </channel>
</rss>
